{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Annotation of Data using JSON Linked Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The Earthcube Geosemantics Framework (http://hcgs.ncsa.illinois.edu/) developed a prototype of a decentralized framework that combines the Linked Data and RESTful web services to annotate, connect, integrate, and reason about integration of geoscience resources. The framework allows the semantic enrichment of web resources and semantic mediation among heterogeneous geoscience resources, such as models and data. \n",
    "\n",
    "This notebook provides examples on how the Semantic Annotation Service can be used to manage linked controlled vocabularies using JSON Linked Data (JSON-LD), including how to query the built-in RDF graphs for existing linked standard vocabularies based on the Community Surface Dynamics Modeling System (CSDMS), Observations Data Model (ODM2) and Unidata udunits2 vocabularies, how to query build-in crosswalks between CSDMS and ODM2 vocabularies using SKOS, and how to add new linked vocabularies to the service. JSON-LD based definitions provided by these endpoints will be used to annotate sample data available within the IML Critical Zone Observatory data repository using the Clowder Web Service API (https://data.imlczo.org/). By supporting JSON-LD, the Semantic Annotation Service and the Clowder framework provide examples on how portable and semantically defined metadata can be used to better annotate data across repositories and services."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "### Geosemantics Framework\n",
    "\n",
    "We face many challenges in the process of extracting meaningful information from data [add examples of challenges related to integration of models and data]. Frequently, these obstacle  compel scientists to perform the integration of models with data manually. Manual integration becomes exponentially difficult when a user aims to integrate long-tail data (data collected by individual researchers or small research groups) and long-tail models (models developed by individuals or small modeling communities). We focus on these long-tail resources because despite their often-narrow scope, they have significant impacts in scientific studies and present an opportunity for addressing critical gaps through automated integration. The goal of the Goesemantics Framework is to provide a framework rooted in semantic techniques and approaches to support “long-tail” models and data integration.\n",
    "\n",
    "### Clowder Data Management Framework\n",
    "\n",
    "\n",
    "### Linked Data\n",
    "\n",
    "The Linked Data paradigm emerged in the context of Semantic Web technologies for publishing and sharing data over the Web. It connects related individual Web resources in a Graph database, where resources represent the graph nodes, and an edge connects a pair of nodes. Publishing and linking scientific resources using Semantic Web technologies require that the user community follows the three principles of Linked Data:\n",
    "\n",
    "1.  Each resource needs to be represented using a unique Uniform Resource Identifier (URI), which consists of: (i) A Uniform Resource Locator (URL) to define the server path over the Web, and (ii) A Uniform Resource Name (URN) to describe the exact name of the resource.\n",
    "\n",
    "2. The relationships between resources are described using the triple format, where a subject S has a predicate P with an object O. A predicate is either an undirected relationship (bi-directional), where it connects two entities in both ways or a directed relationship (uni-directional), where the presence of a relationship between two entities in one direction does not imply the presence of a reverse relationship. The triple format is the structure unit for the Linked Data system. \n",
    "\n",
    "3. The HyperText Transfer Protocol (HTTP) is used as a universal access mechanism for resources on the Web. \n",
    "\n",
    "For more information about linked data, please visit https://www.w3.org/standards/semanticweb/data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Requirements\n",
    "\n",
    "We will be interacting with two web services. The first is the Geosemantics Integration Service (GSIS) available at [http://hcgs.ncsa.illinois.edu](http://hcgs.ncsa.illinois.edu). This service provides support for standandard vocabularies and methods for transforming typical strings used for tracking time, space and physical variables into well formed Linked Data documents. The second service is the [NSF Intensively Managed Landscape Critical Zone Observatory](http://criticalzone.org/iml/) data management system (https://data.imlczo.org/). We will be retrieving data from it and uploading data and metadata back to it using the Clowder web service API.\n",
    "\n",
    "We first setup some basic requirements used through out the notebook. We use the ubiqutous [Requests](https://requests.readthedocs.io/) Python library to intereact with both APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "gsis_host = 'http://hcgs.ncsa.illinois.edu'\n",
    "\n",
    "clowder_host = 'https://data.imlczo.org/clowder'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geosemantics Integration Service (GSIS)\n",
    "\n",
    "Since geospatial data comes in many formats, from shapefiles to geotiffs to comma-delimited text files, it is often helpfull to annotate the files with portable metadata that can be used to identify what each files containes. For geospatial data the temporal, spatial and physical properties dimensions are important and often used to search over a large collection of data. The Geosemantics Integration Service (GSIS) provides a series of endpoints to simplify annotating geospatial data. It includes temporal endpoints so that generic formats for date and times can be translated to well formted JSON-LD formats. It includes the ability to store standard vocabularies as generic RDF graphs and retrieve those as simple JSON documents for easy integration in external services (for example Clowder). It also includes the ability to make links between terms from two different standard vocabularies using SKOS and OWN same as predicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDF Graphs\n",
    "\n",
    "All information stored in the GSIS is stored in the form of RDF graphs using [Apache Jena](https://jena.apache.org/). The following endpoints list all know RDF graphs and let the client retrieve each graph as JSON-LD. The content of these graphs can vary greatly, from standardad vocabularies to definitions of computational models. For a full list of methods please see the documentation available at http://hcgs.ncsa.illinois.edu/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph_names': ['csdms',\n",
       "  'odm2-vars',\n",
       "  'udunits2-base',\n",
       "  'udunits2-derived',\n",
       "  'udunits2-accepted',\n",
       "  'udunits2-prefix',\n",
       "  'google-unit',\n",
       "  'model-2',\n",
       "  'model-3',\n",
       "  'data-1',\n",
       "  'data-2',\n",
       "  'data-3',\n",
       "  'variable_name_crosswalk',\n",
       "  'variable_name_crosswalk-owl',\n",
       "  'variable_name_crosswalk-skos',\n",
       "  'model_test',\n",
       "  'model_test11',\n",
       "  'config_vars.ttl',\n",
       "  'model-x',\n",
       "  'Info',\n",
       "  'Inf',\n",
       "  'demo-model',\n",
       "  'csv-mappings',\n",
       "  'models_graph9d7d400f53864989a05d3ae539f30a78',\n",
       "  'models_graph37baec3114d74ca6abd72cce75f966db',\n",
       "  'models_graphe604316f14334985aaf4ebd6fe220e77',\n",
       "  'models_graph26e29f5026664f11b244072bf6956f74']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a lists of the names of all graphs in the Knowledge base\n",
    "r = requests.get(f\"{gsis_host}/gsis/listGraphNames\")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'@id': 'google-unit:ATA pica', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:ATA point', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Algerian dinar', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Argentine peso', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Astronomical Unit', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Australian cent', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Australian dollar', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:BTU', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Bahrain dinar', '@type': 'google-unit:unit'},\n",
       " {'@id': 'google-unit:Blintz', '@type': 'google-unit:unit'}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the content of a Graph (for example, CSDMS Standard Names)\n",
    "graph = 'google-unit'\n",
    "r = requests.get(f\"{gsis_host}/gsis/read?graph={graph}\")\n",
    "r.json().get('@graph')[0:10] # We just show the top 10 results, to see all results remove the slice operator [0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Vocabularies\n",
    "Two RDF graphs in the GSIS store two external standard vocabularies in RDF. The first one is the [CSDMS Standard Terms (CSN](https://csdms.colorado.edu/wiki/CSDMS_Standard_Names). The second is the [ODM2 Variable Name Vocabulary](http://vocabulary.odm2.org/variablename/). To make it easier to query these RDF by graphs, the GSIS provide simplified methods to search across standard vocabularies by label and look attributes of a specific term in a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['csn:earth_surface_wind__range_of_speed',\n",
       " 'csn:land_surface_wind__reference_height_speed',\n",
       " 'csn:land_surface_wind__speed_reference_height',\n",
       " 'csn:projectile_origin_wind__speed',\n",
       " 'odm2:windGustSpeed',\n",
       " 'odm2:windSpeed']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Search standard vocabularies by search query\n",
    "query = 'wind speed'\n",
    "r = requests.get(f'{gsis_host}/gsis/sas/vars/list?term={query}')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'air__dynamic_shear_viscosity',\n",
       " 'type': 'http://ecgs.ncsa.illinois.edu/2015/csn/name',\n",
       " 'object_fullname': 'air',\n",
       " 'quantity_fullname': 'dynamic_shear_viscosity',\n",
       " 'base_object': 'air',\n",
       " 'base_quantity': 'viscosity',\n",
       " 'object_part': ['air'],\n",
       " 'quantity_part': ['dynamic', 'shear', 'viscosity']}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all properties of a given CSDMS Standard Name from a specific graph\n",
    "graph = 'csdms'\n",
    "name = 'air__dynamic_shear_viscosity'\n",
    "r = requests.get(f\"{gsis_host}/gsis/CSNqueryName?graph={graph}&name={name}\")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of CSDMS Standard Names and ODM2 as JSON Arrays\n",
    "\n",
    "To simplify clients' ability to parse these standard vocabularies, the GSIS provides ways to list all unique identifiers from both vocabularies as play JSON arrays. This for example is used by Clowder to show a list of standard term for each vocabulary in its interface. It is worth nothing that Clowder lets users define these lists through its GUI both as local list, but more importantly as remote JSON endpoints so that as lists are updated the latest version is always shown to the user. Here is an example from the IMLCZO instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air__dielectric_constant',\n",
       " 'air__dynamic_shear_viscosity',\n",
       " 'air__dynamic_volume_viscosity',\n",
       " 'air__kinematic_shear_viscosity',\n",
       " 'air__kinematic_volume_viscosity',\n",
       " 'air__volume-specific_isochoric_heat_capacity',\n",
       " 'air_helium-plume__richardson_number',\n",
       " 'air_radiation~visible__speed',\n",
       " 'air_water~vapor__dew_point_temperature',\n",
       " 'air_water~vapor__saturated_partial_pressure',\n",
       " 'aircraft__flight_duration',\n",
       " 'airfoil__drag_coefficient',\n",
       " 'airfoil__lift_coefficient',\n",
       " 'airfoil_curve~enclosing__circulation',\n",
       " 'airplane__altitude',\n",
       " 'airplane__mach_number',\n",
       " 'airplane_wing__span',\n",
       " 'air~dry__mass-specific_gas_constant',\n",
       " 'air~dry_water~vapor__gas_constant_ratio',\n",
       " 'aluminum__mass-specific_isobaric_heat_capacity']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the CSDMS Standard Names as a flat list.\n",
    "r = requests.get(f\"{gsis_host}/gsis/sas/sn/csn\")\n",
    "csn_terms = r.json()\n",
    "csn_terms[0:20] # We just show the top 20 results, to see all results remove the slice operator [0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['19_Hexanoyloxyfucoxanthin',\n",
       " '1_1_1_Trichloroethane',\n",
       " '1_1_2_2_Tetrachloroethane',\n",
       " '1_1_2_Trichloroethane',\n",
       " '1_1_Dichloroethane',\n",
       " '1_1_Dichloroethene',\n",
       " '1_2_3_Trimethylbenzene',\n",
       " '1_2_4_5_Tetrachlorobenzene',\n",
       " '1_2_4_Trichlorobenzene',\n",
       " '1_2_4_Trimethylbenzene',\n",
       " '1_2_Dibromo_3_Chloropropane',\n",
       " '1_2_Dichlorobenzene',\n",
       " '1_2_Dichloroethane',\n",
       " '1_2_Dichloropropane',\n",
       " '1_2_Dimethylnaphthalene',\n",
       " '1_2_Dinitrobenzene',\n",
       " '1_2_Diphenylhydrazine',\n",
       " '1_3_5_Trimethylbenzene',\n",
       " '1_3_Dichlorobenzene',\n",
       " '1_3_Dimethyladamantane']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the ODM2 Variable Names as a flat list.\n",
    "r = requests.get(f\"{gsis_host}/gsis/sas/sn/odm2\")\n",
    "r.json()[0:20] # We just show the top 20 results, to see all results remove the slice operator [0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some simple Python we can search specific substrings from these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['air_water~vapor__saturated_partial_pressure',\n",
       " 'atmosphere_air_carbon-dioxide__equilibrium_partial_pressure',\n",
       " 'atmosphere_air_carbon-dioxide__partial_pressure',\n",
       " 'atmosphere_air_carbon-dioxide__saturated_partial_pressure',\n",
       " 'atmosphere_air_water~vapor__equilibrium_partial_pressure',\n",
       " 'atmosphere_air_water~vapor__partial_pressure',\n",
       " 'atmosphere_air_water~vapor__saturated_partial_pressure',\n",
       " 'atmosphere_bottom_air_carbon-dioxide__equilibrium_partial_pressure',\n",
       " 'atmosphere_bottom_air_carbon-dioxide__partial_pressure',\n",
       " 'atmosphere_bottom_air_carbon-dioxide__saturated_partial_pressure',\n",
       " 'atmosphere_bottom_air_water~vapor__equilibrium_partial_pressure',\n",
       " 'atmosphere_bottom_air_water~vapor__partial_pressure',\n",
       " 'atmosphere_bottom_air_water~vapor__saturated_partial_pressure',\n",
       " 'atmosphere_carbon-dioxide__partial_pressure',\n",
       " 'atmosphere_water~vapor__partial_pressure',\n",
       " 'atmosphere_water~vapor__saturated_partial_pressure',\n",
       " 'sea_surface_air_carbon-dioxide__partial_pressure',\n",
       " 'sea_surface_air_water~vapor__partial_pressure',\n",
       " 'sea_surface_water_carbon-dioxide__partial_pressure',\n",
       " 'sea_water_carbon-dioxide__partial_pressure']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in csn_terms if 'partial_pressure' in i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Units\n",
    "\n",
    "Physical variables are not the only type of standard vocabularies the GSIS stores. Following are examples of two different lists of standard units imported in the GSIS, [Unidata udunits2](https://www.unidata.ucar.edu/software/udunits/) and [Google Units](https://support.google.com/websearch/answer/3284611?hl=en)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ampere',\n",
       " 'arc_degree',\n",
       " 'arc_minute',\n",
       " 'arc_second',\n",
       " 'candela',\n",
       " 'coulomb',\n",
       " 'day',\n",
       " 'degree_Celsius',\n",
       " 'electronvolt',\n",
       " 'farad',\n",
       " 'gram',\n",
       " 'gray',\n",
       " 'henry',\n",
       " 'hertz',\n",
       " 'hour',\n",
       " 'joule',\n",
       " 'katal',\n",
       " 'kelvin',\n",
       " 'kilogram',\n",
       " 'liter']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of udunits2 units in JSON format.\n",
    "r = requests.get(f\"{gsis_host}/gsis/sas/unit/udunits2\")\n",
    "r.json()[0:20] # We just show the top 20 results, to see all results remove the slice operator [0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acre',\n",
       " 'acre-foot',\n",
       " 'Algerian dinar',\n",
       " 'ampere',\n",
       " 'ampere hour',\n",
       " 'amu',\n",
       " 'arc minute',\n",
       " 'arc second',\n",
       " 'are',\n",
       " 'Argentine peso',\n",
       " 'Astronomical Unit',\n",
       " 'ATA pica',\n",
       " 'ATA point',\n",
       " 'atmosphere',\n",
       " 'atomic mass unit',\n",
       " 'Australian cent',\n",
       " 'Australian dollar',\n",
       " 'Bahrain dinar',\n",
       " \"baker's dozen\",\n",
       " 'bar']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the list of Google units in JSON format.\n",
    "r = requests.get(gsis_host + \"/gsis/sas/unit/google\")\n",
    "r.json()[0:20] # We just show the top 20 results, to see all results remove the slice operator [0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Annotation\n",
    "\n",
    "To convert from strings representing time to a more formal definition the GSIS provides three endpoints to represent instant, interval and time series. Time values are represented in UTC (Coordinated Universal Time) format. Times are expressed in local time, together with a time zone offset in hours and minutes. For more information, please visit https://www.w3.org/TR/NOTE-datetime for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Instant Annotation\n",
    "Query parameters: \n",
    "* **time** (string): time value in UTC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': {'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  'dcterms': 'http://purl.org/dc/terms/',\n",
       "  'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
       "  'time': 'http://www.w3.org/2006/time#',\n",
       "  'tzont': 'http://www.w3.org/2006/timezone-us'},\n",
       " '@id': 'http://ecgs.ncsa.illinois.edu/time_instant',\n",
       " '@type': 'time:Instant',\n",
       " 'dc:date': \"yyyy-MM-dd'T'HH:mm:ssZ\",\n",
       " 'time:DateTimeDescription': {'time:year': '2014',\n",
       "  'time:month': '1',\n",
       "  'time:day': '1',\n",
       "  'tzont': '-09:00',\n",
       "  'time:hours': '8',\n",
       "  'time:minutes': '1',\n",
       "  'time:seconds': '1'}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a temporal annotation for a time instant in a JSON-LD format.\n",
    "time = '2014-01-01T08:01:01-09:00'\n",
    "r = requests.get(f\"{gsis_host}/gsis/sas/temporal?time={time}\")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Interval Annotation\n",
    "Query parameters: \n",
    "* **beginning** (string): time value in UTC format.\n",
    "* **end** (string): time value in UTC format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': {'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  'dcterms': 'http://purl.org/dc/terms/',\n",
       "  'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
       "  'time': 'http://www.w3.org/2006/time#',\n",
       "  'tzont': 'http://www.w3.org/2006/timezone-us'},\n",
       " '@id': 'http://ecgs.ncsa.illinois.edu/time_interval',\n",
       " '@type': 'time:Interval',\n",
       " 'time:Duration': {'time:hasBeginning': {'dc:date': \"yyyy-MM-dd'T'HH:mm:ssZ\",\n",
       "   'time:DateTimeDescription': {'time:year': 2014,\n",
       "    'time:month': 1,\n",
       "    'time:day': 1,\n",
       "    'tzont': '-10:00',\n",
       "    'time:hours': 8,\n",
       "    'time:minutes': 1,\n",
       "    'time:seconds': 1}},\n",
       "  'time:hasEnd': {'dc:date': \"yyyy-MM-dd'T'HH:mm:ssZ\",\n",
       "   'time:DateTimeDescription': {'time:year': 2014,\n",
       "    'time:month': 12,\n",
       "    'time:day': 31,\n",
       "    'tzont': '-10:00',\n",
       "    'time:hours': 8,\n",
       "    'time:minutes': 1,\n",
       "    'time:seconds': 1}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a temporal annotation for a time interval in a JSON-LD format.\n",
    "beginning = '2014-01-01T08:01:01-10:00'\n",
    "end = '2014-12-31T08:01:01-10:00'\n",
    "r = requests.get(f\"{gsis_host}/gsis/sas/temporal?beginning={beginning}&end={end}\")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Annotation\n",
    "Query parameters:\n",
    "* **beginning** (string): time value in UTC format.\n",
    "* **end** (string): time value in UTC format.\n",
    "* **interval** (float): time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': {'dc': 'http://purl.org/dc/elements/1.1/',\n",
       "  'dcterms': 'http://purl.org/dc/terms/',\n",
       "  'xsd': 'http://www.w3.org/2001/XMLSchema#',\n",
       "  'time': 'http://www.w3.org/2006/time#',\n",
       "  'tzont': 'http://www.w3.org/2006/timezone-us'},\n",
       " '@id': 'http://ecgs.ncsa.illinois.edu/time_series',\n",
       " 'time:Duration': {'time:hasBeginning': {'dc:date': \"yyyy-MM-dd'T'HH:mm:ssZ\",\n",
       "   'time:DateTimeDescription': {'time:year': 2014,\n",
       "    'time:month': 1,\n",
       "    'time:day': 1,\n",
       "    'tzont': '-10:00',\n",
       "    'time:hours': 8,\n",
       "    'time:minutes': 1,\n",
       "    'time:seconds': 1}},\n",
       "  'time:hasEnd': {'dc:date': \"yyyy-MM-dd'T'HH:mm:ssZ\",\n",
       "   'time:DateTimeDescription': {'time:year': 2014,\n",
       "    'time:month': 3,\n",
       "    'time:day': 1,\n",
       "    'tzont': '-10:00',\n",
       "    'time:hours': 8,\n",
       "    'time:minutes': 1,\n",
       "    'time:seconds': 1}},\n",
       "  'time:temporalUnit': {'@type': 'time:unitSecond', '@value': 4}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a temporal annotation for a time series in a JSON-LD format.\n",
    "beginning = '2014-01-01T08:01:01-10:00'\n",
    "end = '2014-03-01T08:01:01-10:00'\n",
    "interval = '4'\n",
    "r = requests.get(f\"{gsis_host}/gsis/sas/temporal?beginning={beginning}&end={end}&interval={interval}\")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clowder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we will be adding information to the Clowder instance, we will be required to register an account on the IMLCZO Clowder instance and create an API key and added to the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "# Please create an API key as described above\n",
    "# If using a .env file is confusing you can manually set the key\n",
    "# clowder_key = 'copy and paste your key here'\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import os\n",
    "clowder_key = os.getenv(\"CLOWDER-KEY\")\n",
    "\n",
    "headers = {'Content-type': 'application/json', 'X-API-Key': clowder_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search by metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search by keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count': 8,\n",
       " 'size': 8,\n",
       " 'scanned_size': 240,\n",
       " 'results': [{'id': '56d79957e4b0b55c0889bea2',\n",
       "   'name': 'Test dataset',\n",
       "   'description': 'Testing permissions',\n",
       "   'created': 'Wed Mar 02 19:54:31 CST 2016',\n",
       "   'thumbnail': '56d79975e4b0b55c0889bec7',\n",
       "   'authorId': '53adb361bb0d14bfccb04617',\n",
       "   'spaces': ['56d7987ee4b0b55c0889bea0'],\n",
       "   'resource_type': 'dataset'},\n",
       "  {'id': '5ebb1c2d4f0c0ce4611383bb',\n",
       "   'collectionname': 'Tests',\n",
       "   'description': 'tests',\n",
       "   'created': 'Tue May 12 16:59:09 CDT 2020',\n",
       "   'thumbnail': None,\n",
       "   'authorId': '53adb361bb0d14bfccb04617',\n",
       "   'resource_type': 'collection'},\n",
       "  {'id': '56d79976e4b0b55c0889bed1',\n",
       "   'name': 'carbon-emissions.pdf',\n",
       "   'status': 'PROCESSED',\n",
       "   'thumbnail': '56d79977e4b0b55c0889bee8',\n",
       "   'created': 'Wed Mar 02 19:55:02 CST 2016',\n",
       "   'resource_type': 'file'},\n",
       "  {'id': '5979f72a4f0c2e3a97a0948a',\n",
       "   'name': 'dinoskull.obj',\n",
       "   'status': 'PROCESSED',\n",
       "   'thumbnail': None,\n",
       "   'created': 'Thu Jul 27 09:22:34 CDT 2017',\n",
       "   'resource_type': 'file'},\n",
       "  {'id': '5ebc21604f0c0ce4611411c7',\n",
       "   'name': 'new dataset',\n",
       "   'description': '...',\n",
       "   'created': 'Wed May 13 11:33:36 CDT 2020',\n",
       "   'thumbnail': None,\n",
       "   'authorId': '53adb361bb0d14bfccb04617',\n",
       "   'spaces': ['5ebb1c114f0c0ce46113839d'],\n",
       "   'resource_type': 'dataset'},\n",
       "  {'id': '570e6218e4b0ed483bd2d697',\n",
       "   'name': 'Test dataset out of collection',\n",
       "   'description': 'test',\n",
       "   'created': 'Wed Apr 13 10:13:28 CDT 2016',\n",
       "   'thumbnail': None,\n",
       "   'authorId': '5500f508e4b0feb5ae154566',\n",
       "   'spaces': ['570e60d4e4b0ed483bd2d677'],\n",
       "   'resource_type': 'dataset'},\n",
       "  {'id': '5acd17ac4f0cb29fd0e6232d',\n",
       "   'name': 'Upload Test',\n",
       "   'description': '',\n",
       "   'created': 'Tue Apr 10 14:59:40 CDT 2018',\n",
       "   'thumbnail': '5b4a049f4f0c2e0ff56c29ea',\n",
       "   'authorId': '53adb361bb0d14bfccb04617',\n",
       "   'spaces': [],\n",
       "   'resource_type': 'dataset'},\n",
       "  {'id': '5e441cf04f0c18596b30fb83',\n",
       "   'name': 'Test',\n",
       "   'description': '',\n",
       "   'created': 'Wed Feb 12 09:42:40 CST 2020',\n",
       "   'thumbnail': None,\n",
       "   'authorId': '53adb361bb0d14bfccb04617',\n",
       "   'spaces': [],\n",
       "   'resource_type': 'dataset'}],\n",
       " 'from': 0,\n",
       " 'total_size': 8}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'test'\n",
    "url = \"{}/api/search?query={}\".format(clowder_host, query)\n",
    "r = requests.get(url, headers=headers)\n",
    "r.raise_for_status()\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search by `ODM2 Variable Name = precipitation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset id: 596faa3b4f0c0b1c81fa42de\n"
     ]
    }
   ],
   "source": [
    "query = '\"ODM2 Variable Name\":\"precipitation\"'\n",
    "url = \"{}/api/search?query={}\".format(clowder_host, query)\n",
    "r = requests.get(url, headers=headers)\n",
    "search = r.json()\n",
    "datasetId = search.get('results')[0].get('id')\n",
    "print('Dataset id: ' + datasetId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset id: 596faa3b4f0c0b1c81fa42de\n"
     ]
    }
   ],
   "source": [
    "query = '\"ODM2 Variable Name\":\"precipitation\"'\n",
    "url = \"{}/api/search?query={}\".format(clowder_host, query)\n",
    "r = requests.get(url, headers=headers)\n",
    "search = r.json()\n",
    "datasetId = search.get('results')[0].get('id')\n",
    "print('Dataset id: ' + datasetId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2211973"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List files in dataset\n",
    "url = \"{}/api/datasets/{}/files\".format(clowder_host, datasetId)\n",
    "r = requests.get(url)\n",
    "files = r.json()\n",
    "# Download the first file\n",
    "fileId = files[0].get('id')\n",
    "fileName = files[0].get('filename')\n",
    "url = \"{}/api/files/{}/blob\".format(clowder_host, fileId)\n",
    "r = requests.get(url)\n",
    "open(fileName, 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(name, description, access, space, collection):\n",
    "    '''\n",
    "     params: name, description, access: PUBLIC vs PRIVATE, \n",
    "         space: a list of string can be empty,\n",
    "         collection: a list of string, can be empty\n",
    "    '''\n",
    "    url = \"{}/api/datasets/createempty\".format(clowder_host)\n",
    "    payload = json.dumps({'name':name, \n",
    "                          'description':description,\n",
    "                          'access':access,\n",
    "                          'space':space,\n",
    "                          'collection':collection}) \n",
    "\n",
    "    r = requests.post(url,\n",
    "                     data=payload,\n",
    "                     headers=headers)\n",
    "    print(r.status_code)\n",
    "    print(r.text)\n",
    "    return r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\"id\":\"5ebd9c624f0c0ce46114e55c\"}\n",
      "View at https://data.imlczo.org/clowder/datasets/5ebd9c624f0c0ce46114e55c\n"
     ]
    }
   ],
   "source": [
    "new_dataset = create_dataset(name=\"new dataset\", description=\"...\", access=\"PRIVATE\", \n",
    "               space=['5ebb1c114f0c0ce46113839d'],\n",
    "              collection=['5ebb1c2d4f0c0ce4611383bb'])\n",
    "new_dataset_id = new_dataset.get('id')\n",
    "print(f'View at {clowder_host}/datasets/{new_dataset_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload file to new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"{}/api/uploadToDataset/{}\".format(clowder_host, new_dataset_id)\n",
    "files = {'file': open(fileName, 'rb')}\n",
    "r = requests.post(url, files=files, headers={'X-API-Key': clowder_key})\n",
    "r.raise_for_status()\n",
    "print(r.json())\n",
    "fileId = r.json().get('id')\n",
    "print(f'View at {clowder_host}/files/{fileId}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add metadata to new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metadata successfully added to db'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "url = \"{}/api/files/{}/metadata.jsonld\".format(clowder_host, fileId)\n",
    "payload = {\n",
    "    \"@context\":[\n",
    "        \"https://clowder.ncsa.illinois.edu/contexts/metadata.jsonld\"\n",
    "    ],\n",
    "    \"agent\":{\n",
    "        \"@type\":\"cat:extractor\",\n",
    "        \"name\":\"ECGS Notebook\",\n",
    "        \"extractor_id\":\"https://clowder.ncsa.illinois.edu/api/extractors/ecgs\"\n",
    "    },\n",
    "    \"content\":{\n",
    "        \"foo\": \"bar\"\n",
    "    }\n",
    "}\n",
    "r = requests.post(url, headers = headers, data=json.dumps(payload))\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'@context': {'cat': 'https://clowder.ncsa.illinois.edu/#',\n",
       "  'extractor_id': {'@id': 'cat:extractor/id', '@type': '@id'},\n",
       "  'user_id': {'@id': 'cat:user/id', '@type': '@id'},\n",
       "  'created_at': {'@id': 'http://purl.org/dc/terms/created',\n",
       "   '@type': 'http://www.w3.org/2001/XMLSchema#dateTime'},\n",
       "  'agent': {'@id': 'http://www.w3.org/ns/prov#Agent'},\n",
       "  'user': 'cat:user',\n",
       "  'extractor': 'cat:extractor',\n",
       "  'content': {'@id': 'https://clowder.ncsa.illinois.edu/metadata#content'}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The context file describes the basic elements of a Clowder metadata document\n",
    "r = requests.get('https://clowder.ncsa.illinois.edu/contexts/metadata.jsonld')\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "This short notebook provides a few simple examples of developing web applications around the principles of Linked Data. By developing services built around interoperability we hope it will be easier in the future to build services that can easily interoperate. Earth sciences provide unique challenges in that the way researchers store their data can vary greatly. The Linked Data approach can be useful in overcoming some of these challenges even thought it provides its own technical challenges in terms of adoption. Over time efforts like [Schema.org](https://schema.org/) are showing the the principles of Linked Data are important but that simplifying some of their approaches might be the key to widespread adoption. Even though the GSIS stores information as RDF graphs, it provides simple HTTP web services to make it easier to be used in the existing ecosystem of tools. Furthermore, the Clowder data framework provides simple GUI and APIs to store rich metadata documents next to the raw bytes, but it tries to find a good compromose between expressivenes of the metadata and simplicity of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
